{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "251f79b4",
   "metadata": {},
   "source": [
    "Blok 1: KÃ¼tÃ¼phaneler ve Dosya YollarÄ±\n",
    "\n",
    "Ã–nce temel araÃ§larÄ±mÄ±zÄ± Ã§aÄŸÄ±ralÄ±m ve yollarÄ± tanÄ±mlayalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b4e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Keras'Ä± doÄŸrudan tf Ã¼zerinden Ã§aÄŸÄ±ralÄ±m (Pylance bunu daha kolay anlar)\n",
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "applications = keras.applications\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics # sklearn kuruluysa sarÄ± Ã§izgi gitmeli\n",
    "\n",
    "# Dosya yollarÄ±\n",
    "LIDAR_PATH = r\"C:\\Users\\alkay\\ITU_C\\chactun\\data\\Chactun_ML_ready_lidar\\lidar\"\n",
    "MASK_PATH = r\"C:\\Users\\alkay\\ITU_C\\chactun\\data\\Chactun_ML_ready_masks\\masks\"\n",
    "\n",
    "# EÄŸitim ve Test sÄ±nÄ±rlarÄ±\n",
    "TRAIN_END = 1764\n",
    "TEST_END = 2093"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8e1a59",
   "metadata": {},
   "source": [
    "Blok 2: Veri YÃ¼kleme Fonksiyonu\n",
    "\n",
    "Bu blokta .tif dosyalarÄ±nÄ± okuyup, maskeleri birleÅŸtirip (3 kanallÄ± hale getirip) normalleÅŸtireceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f364d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 35s 0us/step\n",
      "VGG-19 tabanlÄ± U-Net baÅŸarÄ±yla oluÅŸturuldu!\n",
      "Model: \"VGG19_UNET\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 224, 224, 3)  0           ['input_1[0][0]',                \n",
      "                                                                  'input_1[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 224, 224, 64  1792        ['concatenate[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 224, 224, 64  36928       ['block1_conv1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 112, 112, 64  0           ['block1_conv2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 112, 112, 12  73856       ['block1_pool[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 112, 112, 12  147584      ['block2_conv1[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 56, 56, 128)  0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 56, 56, 256)  295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv4 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 28, 28, 256)  0           ['block3_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 28, 28, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv4 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 14, 14, 512)  0           ['block4_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 14, 14, 512)  2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv4 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 28, 28, 512)  0           ['block5_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 28, 28, 1024  0           ['up_sampling2d[0][0]',          \n",
      "                                )                                 'block4_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 28, 28, 512)  4719104     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 28, 28, 512)  2359808     ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 56, 56, 512)  0          ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 56, 56, 768)  0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'block3_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 56, 56, 256)  1769728     ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 56, 56, 256)  590080      ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 112, 112, 25  0          ['conv2d_3[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 112, 112, 38  0           ['up_sampling2d_2[0][0]',        \n",
      "                                4)                                'block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 112, 112, 12  442496      ['concatenate_3[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 112, 112, 12  147584      ['conv2d_4[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 12  0          ['conv2d_5[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 224, 224, 19  0           ['up_sampling2d_3[0][0]',        \n",
      "                                2)                                'block1_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 224, 224, 64  110656      ['concatenate_4[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 224, 224, 64  36928       ['conv2d_6[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 224, 224, 3)  195         ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,200,963\n",
      "Trainable params: 30,200,963\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_vgg19_unet(input_shape=(224, 224, 1)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 1 kanallÄ± LiDAR verisini VGG19'un beklediÄŸi 3 kanallÄ± yapÄ±ya Ã§oÄŸaltÄ±yoruz\n",
    "    x_3ch = layers.Concatenate()([inputs, inputs, inputs])\n",
    "    \n",
    "    # Encoder: Ã–nceden eÄŸitilmiÅŸ VGG19\n",
    "    vgg19 = applications.VGG19(include_top=False, weights='imagenet', input_tensor=x_3ch)\n",
    "    \n",
    "    # VGG19'dan Skip Connection (Atlama BaÄŸlantÄ±larÄ±) iÃ§in Ã§Ä±kÄ±ÅŸlarÄ± alÄ±yoruz\n",
    "    s1 = vgg19.get_layer(\"block1_conv2\").output # (224, 224, 64)\n",
    "    s2 = vgg19.get_layer(\"block2_conv2\").output # (112, 112, 128)\n",
    "    s3 = vgg19.get_layer(\"block3_conv4\").output # (56, 56, 256)\n",
    "    s4 = vgg19.get_layer(\"block4_conv4\").output # (28, 28, 512)\n",
    "    \n",
    "    # Bridge (KÃ¶prÃ¼)\n",
    "    b1 = vgg19.get_layer(\"block5_conv4\").output # (14, 14, 512)\n",
    "    \n",
    "    # Decoder (Ã‡Ã¶zÃ¼cÃ¼) KatmanlarÄ±\n",
    "    # UpBlock 1\n",
    "    d1 = layers.UpSampling2D((2, 2))(b1)\n",
    "    d1 = layers.concatenate([d1, s4])\n",
    "    d1 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(d1)\n",
    "    d1 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(d1)\n",
    "    \n",
    "    # UpBlock 2\n",
    "    d2 = layers.UpSampling2D((2, 2))(d1)\n",
    "    d2 = layers.concatenate([d2, s3])\n",
    "    d2 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(d2)\n",
    "    d2 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(d2)\n",
    "    \n",
    "    # UpBlock 3\n",
    "    d3 = layers.UpSampling2D((2, 2))(d2)\n",
    "    d3 = layers.concatenate([d3, s2])\n",
    "    d3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(d3)\n",
    "    d3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(d3)\n",
    "    \n",
    "    # UpBlock 4\n",
    "    d4 = layers.UpSampling2D((2, 2))(d3)\n",
    "    d4 = layers.concatenate([d4, s1])\n",
    "    d4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(d4)\n",
    "    d4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(d4)\n",
    "    \n",
    "    # Ã‡Ä±kÄ±ÅŸ KatmanÄ±: 3 maske sÄ±nÄ±fÄ± var, baÄŸÄ±msÄ±z olasÄ±lÄ±klar iÃ§in Sigmoid kullanÄ±yoruz\n",
    "    outputs = layers.Conv2D(3, (1, 1), activation='sigmoid')(d4)\n",
    "    \n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs], name=\"VGG19_UNET\")\n",
    "    return model\n",
    "\n",
    "# Modeli oluÅŸtur\n",
    "model = build_vgg19_unet()\n",
    "\n",
    "# Optimizer ve Loss fonksiyonu ayarlarÄ±\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "                  loss='binary_crossentropy', \n",
    "              metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=2)])\n",
    "\n",
    "print(\"VGG-19 tabanlÄ± U-Net baÅŸarÄ±yla oluÅŸturuldu!\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc1d74f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU AlgÄ±landÄ±: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(f\"âœ… GPU AlgÄ±landÄ±: {gpu_devices}\")\n",
    "else:\n",
    "    print(\"âŒ GPU AlgÄ±lanamadÄ±, CPU kullanÄ±lacak.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563357c",
   "metadata": {},
   "source": [
    "Blok 3: VGG-19 TabanlÄ± U-Net Modeli\n",
    "\n",
    "VGG-19'un ilk katmanlarÄ±nÄ± \"Encoder\" (Ã¶zellik Ã§Ä±karÄ±cÄ±) olarak kullanacaÄŸÄ±z. Segmentasyon yaptÄ±ÄŸÄ±mÄ±z iÃ§in gÃ¶rÃ¼ntÃ¼yÃ¼ tekrar eski boyutuna getiren bir \"Decoder\" eklememiz gerekiyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859ba515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EÄŸitim sÃ¼reci baÅŸlatÄ±lÄ±yor... RTX 4060 devreye giriyor ðŸš€\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 38\u001b[0m\n\u001b[0;32m     34\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEÄŸitim sÃ¼reci baÅŸlatÄ±lÄ±yor... RTX 4060 devreye giriyor ðŸš€\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m---> 38\u001b[0m     \u001b[43mtrain_gen\u001b[49m,                   \u001b[38;5;66;03m# Blok 2'deki eÄŸitim jeneratÃ¶rÃ¼\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mtest_gen,    \u001b[38;5;66;03m# Blok 2'deki test (doÄŸrulama) jeneratÃ¶rÃ¼\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[0;32m     41\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[checkpoint, early_stop, reduce_lr],\n\u001b[0;32m     42\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     43\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_gen' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# En iyi modelin kaydedileceÄŸi klasÃ¶rÃ¼ oluÅŸturalÄ±m\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "# EÄŸitim AsistanlarÄ± (Callbacks)\n",
    "# 1. Her epoch sonunda sadece en iyi modeli (val_loss'a gÃ¶re) kaydeder\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"checkpoints/vgg19_unet_best.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 2. Model 10 tur boyunca ilerleme kaydetmezse eÄŸitimi erken bitirir\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 3. EÄŸitim duraklarsa Ã¶ÄŸrenme oranÄ±nÄ± (learning rate) dÃ¼ÅŸÃ¼rerek ince ayar yapar\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# EÄŸitimi BaÅŸlatÄ±yoruz!\n",
    "EPOCHS = 50\n",
    "print(\"EÄŸitim sÃ¼reci baÅŸlatÄ±lÄ±yor... RTX 4060 devreye giriyor ðŸš€\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,                   # Blok 2'deki eÄŸitim jeneratÃ¶rÃ¼\n",
    "    validation_data=test_gen,    # Blok 2'deki test (doÄŸrulama) jeneratÃ¶rÃ¼\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b74d7",
   "metadata": {},
   "source": [
    "Blok 4: EÄŸitim (Training)\n",
    "\n",
    "Modeli eÄŸitmeye baÅŸlayalÄ±m. Arkeolojik verilerde nesneler seyrek olduÄŸu iÃ§in binary_crossentropy baÅŸlangÄ±Ã§ iÃ§in iyidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bdd38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    validation_data=(X_test, y_test), \n",
    "    epochs=25, \n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# EÄŸitim sonucunu gÃ¶rselleÅŸtir\n",
    "plt.plot(history.history['loss'], label='EÄŸitim KaybÄ±')\n",
    "plt.plot(history.history['val_loss'], label='DoÄŸrulama KaybÄ±')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8966b297",
   "metadata": {},
   "source": [
    "### Analizler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e594a54",
   "metadata": {},
   "source": [
    "1. SayÄ±sal Analiz: IoU (Intersection over Union) Skoru\n",
    "Segmentasyonun \"altÄ±n standardÄ±\" IoU (KesiÅŸim bÃ¶lÃ¼ BirleÅŸim) deÄŸeridir. Bu, modelin tahmin ettiÄŸi maske ile gerÃ§ek maskenin ne kadar Ã¼st Ã¼ste bindiÄŸini Ã¶lÃ§er."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5245ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "def calculate_iou(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Tahminleri 0.5 eÅŸiÄŸiyle 0 veya 1'e Ã§evirelim\n",
    "    y_pred_thresholded = (y_pred > 0.5).astype(np.uint8)\n",
    "    \n",
    "    classes = ['Building', 'Aguada', 'Platform']\n",
    "    ious = []\n",
    "    \n",
    "    print(\"\\n--- SINIF BAZLI IoU SKORLARI ---\")\n",
    "    for i, class_name in enumerate(classes):\n",
    "        # Her sÄ±nÄ±f iÃ§in IoU hesapla\n",
    "        iou = jaccard_score(y_test[..., i].flatten(), y_pred_thresholded[..., i].flatten(), pos_label=1)\n",
    "        ious.append(iou)\n",
    "        print(f\"{class_name} IoU: {iou:.4f}\")\n",
    "    \n",
    "    print(f\"\\nOrtalama (Mean) IoU: {np.mean(ious):.4f}\")\n",
    "\n",
    "# Modeli test verisiyle deÄŸerlendir\n",
    "calculate_iou(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f2a546",
   "metadata": {},
   "source": [
    "2. GÃ¶rselleÅŸtirme: Tahminleri KarÅŸÄ±laÅŸtÄ±rma\n",
    "Modelin neyi doÄŸru, neyi yanlÄ±ÅŸ bildiÄŸini gÃ¶rmenin en iyi yolu; Orijinal LiDAR, GerÃ§ek Maske ve Modelin Tahminini yan yana koymaktÄ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50e60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(model, X_test, y_test, num_samples=3):\n",
    "    # Rastgele Ã¶rnekler seÃ§\n",
    "    indices = np.random.randint(0, len(X_test), num_samples)\n",
    "    y_pred = model.predict(X_test[indices])\n",
    "    y_pred_thresholded = (y_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(15, 5 * num_samples))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        # 1. SÃ¼tun: Orijinal LiDAR\n",
    "        plt.subplot(num_samples, 3, i*3 + 1)\n",
    "        plt.imshow(X_test[idx].squeeze(), cmap='gray')\n",
    "        plt.title(f\"Ã–rnek {idx}: Orijinal LiDAR\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # 2. SÃ¼tun: GerÃ§ek Maske (Ground Truth)\n",
    "        # SÄ±nÄ±flarÄ± renkli gÃ¶rmek iÃ§in 3 kanalÄ± da gÃ¶steriyoruz\n",
    "        plt.subplot(num_samples, 3, i*3 + 2)\n",
    "        plt.imshow(y_test[idx])\n",
    "        plt.title(\"GerÃ§ek Maske\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # 3. SÃ¼tun: Modelin Tahmini\n",
    "        plt.subplot(num_samples, 3, i*3 + 3)\n",
    "        plt.imshow(y_pred_thresholded[i])\n",
    "        plt.title(\"Model Tahmini\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Tahminleri gÃ¶rselleÅŸtir\n",
    "visualize_results(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed61dd0",
   "metadata": {},
   "source": [
    "3. EÄŸitim Analizi: Loss ve Accuracy Grafikleri\n",
    "EÄŸitim sÄ±rasÄ±nda modelin \"ezberleyip ezberlemediÄŸini\" (overfitting) anlamak iÃ§in bu grafikleri Ã§izdirmeliyiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8fe479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Loss GrafiÄŸi\n",
    "    ax1.plot(history.history['loss'], label='Train Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Val Loss')\n",
    "    ax1.set_title('Model KaybÄ± (Loss)')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend()\n",
    "\n",
    "    # Accuracy GrafiÄŸi\n",
    "    ax2.plot(history.history['accuracy'], label='Train Acc')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    ax2.set_title('Model DoÄŸruluÄŸu (Accuracy)')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
