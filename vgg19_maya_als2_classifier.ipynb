{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf4ab982",
   "metadata": {},
   "source": [
    "### GPU or CPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67ac4fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaÅŸarÄ±yla eklendi: Windows artÄ±k C:\\Users\\alkay\\miniconda3\\envs\\ai_env\\Library\\bin klasÃ¶rÃ¼nÃ¼ gÃ¶rÃ¼yor.\n",
      "Bulunan GPU SayÄ±sÄ±:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Anaconda ortamÄ±nÄ±n (ai_env) kurulu olduÄŸu ana dizini buluyoruz\n",
    "conda_prefix = os.environ.get('CONDA_PREFIX')\n",
    "\n",
    "if conda_prefix:\n",
    "    # NVIDIA CUDA ve cuDNN .dll dosyalarÄ±nÄ±n saklandÄ±ÄŸÄ± klasÃ¶r\n",
    "    library_bin = os.path.join(conda_prefix, 'Library', 'bin')\n",
    "    \n",
    "    # Python'a \"Bu klasÃ¶rÃ¼n iÃ§ine de bak\" diyoruz\n",
    "    if os.path.exists(library_bin):\n",
    "        os.add_dll_directory(library_bin)\n",
    "        print(f\"BaÅŸarÄ±yla eklendi: Windows artÄ±k {library_bin} klasÃ¶rÃ¼nÃ¼ gÃ¶rÃ¼yor.\")\n",
    "else:\n",
    "    print(\"UYARI: CONDA_PREFIX bulunamadÄ±. LÃ¼tfen Anaconda ortamÄ±nda olduÄŸundan emin ol.\")\n",
    "\n",
    "# YollarÄ± tanÄ±ttÄ±ktan SONRA TensorFlow'u Ã§aÄŸÄ±rÄ±yoruz\n",
    "import tensorflow as tf\n",
    "print(\"Bulunan GPU SayÄ±sÄ±: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac7c97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UYARI: GPU bulunamadÄ±! Ä°ÅŸlemler CPU'da yapÄ±lacak.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# GPU'larÄ± listele\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(f\"Harika! GPU Bulundu: {gpus[0]}\")\n",
    "    # BelleÄŸin sadece gerektiÄŸi kadar kullanÄ±lmasÄ±nÄ± saÄŸla (VRAM iÅŸgalini Ã¶nler)\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"Bellek bÃ¼yÃ¼mesi (Memory Growth) aktif edildi.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"UYARI: GPU bulunamadÄ±! Ä°ÅŸlemler CPU'da yapÄ±lacak.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3102ee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulunan GPU SayÄ±sÄ±:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Bulunan GPU SayÄ±sÄ±: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a4dd2",
   "metadata": {},
   "source": [
    "### Blok 1: KÃ¼tÃ¼phaneler ve Ayarlar\n",
    "Bu blok, projemiz iÃ§in gereken tÃ¼m derin Ã¶ÄŸrenme (TensorFlow/Keras) ve gÃ¶rÃ¼ntÃ¼ iÅŸleme (OpenCV) kÃ¼tÃ¼phanelerini iÃ§e aktarÄ±r. AyrÄ±ca modelin eÄŸitiminde kullanÄ±lacak LiDAR (Girdi) ve Maske (Ã‡Ä±ktÄ±/Ground Truth) verilerinin bilgisayardaki dosya yollarÄ±nÄ± tanÄ±mlar. Veri setinin train (eÄŸitim) ve test olarak hangi indekslerden bÃ¶lÃ¼neceÄŸi burada belirlenir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f70b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Keras'Ä± doÄŸrudan tf Ã¼zerinden Ã§aÄŸÄ±ralÄ±m (Pylance bunu daha kolay anlar)\n",
    "from tensorflow import keras\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "applications = keras.applications\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics # sklearn kuruluysa sarÄ± Ã§izgi gitmeli\n",
    "\n",
    "# Dosya yollarÄ±\n",
    "LIDAR_PATH = r\"C:\\Users\\alkay\\ITU_C\\chactun\\data\\Chactun_ML_ready_lidar\\lidar\"\n",
    "MASK_PATH = r\"C:\\Users\\alkay\\ITU_C\\chactun\\data\\Chactun_ML_ready_masks\\masks\"\n",
    "\n",
    "# EÄŸitim ve Test sÄ±nÄ±rlarÄ±\n",
    "TRAIN_END = 1764\n",
    "TEST_END = 2093"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc18c618",
   "metadata": {},
   "source": [
    "### Blok 2: Veri YÃ¼kleyici (Data Generator)\n",
    "Bu blok, donanÄ±m sÄ±nÄ±rlarÄ±nÄ± (RAM/VRAM) aÅŸmamak iÃ§in Ã¶zel bir Veri JeneratÃ¶rÃ¼ (`ChactunDataGenerator`) oluÅŸturur. \n",
    "* TÃ¼m veri setini RAM'e yÃ¼klemek yerine, eÄŸitim sÄ±rasÄ±nda gÃ¶rÃ¼ntÃ¼leri belirlenen `batch_size` (yÄ±ÄŸÄ±n boyutu) kadar diskten anlÄ±k olarak Ã§eker.\n",
    "* Ã‡Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼ `480x480` olarak ayarlar. YÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼k RTX 4060'Ä±n 8GB VRAM'ini zorlayacaÄŸÄ± iÃ§in `batch_size=2` olarak optimize edilmiÅŸtir.\n",
    "* Siyah (0) olan maskeleri 1 (Pozitif SÄ±nÄ±f) olarak matematiksel olarak tersine Ã§evirir (Invert)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6009c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EÄŸitim ve Test JeneratÃ¶rleri hazÄ±rlanÄ±yor...\n",
      "JeneratÃ¶rler HazÄ±r! YÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ ve bellek dostu veri yÃ¼kleme aktif.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class ChactunDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, lidar_dir, mask_dir, start_idx, end_idx, batch_size=2, img_size=(480, 480)):\n",
    "        self.lidar_dir = lidar_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.indices = list(range(start_idx, end_idx + 1))\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indices) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        # X: (batch_size, 480, 480, 1), Y: (batch_size, 480, 480, 3)\n",
    "        X = np.empty((len(batch_indices), *self.img_size, 1), dtype=np.float32)\n",
    "        Y = np.empty((len(batch_indices), *self.img_size, 3), dtype=np.float32)\n",
    "\n",
    "        for i, tile_idx in enumerate(batch_indices):\n",
    "            # 1. LiDAR GÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ Oku ve Ä°ÅŸle\n",
    "            lidar_path = os.path.join(self.lidar_dir, f\"tile_{tile_idx}_lidar.tif\")\n",
    "            lidar_img = cv2.imread(lidar_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if lidar_img is None:\n",
    "                lidar_img = np.zeros(self.img_size, dtype=np.uint8)\n",
    "                \n",
    "            lidar_img = cv2.resize(lidar_img, self.img_size)\n",
    "            X[i,] = np.expand_dims(lidar_img / 255.0, axis=-1)\n",
    "\n",
    "            # 2. Maskeleri Oku\n",
    "            m_building = cv2.imread(os.path.join(self.mask_dir, f\"tile_{tile_idx}_mask_building.tif\"), cv2.IMREAD_GRAYSCALE)\n",
    "            m_aguada = cv2.imread(os.path.join(self.mask_dir, f\"tile_{tile_idx}_mask_aguada.tif\"), cv2.IMREAD_GRAYSCALE)\n",
    "            m_platform = cv2.imread(os.path.join(self.mask_dir, f\"tile_{tile_idx}_mask_platform.tif\"), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if m_building is None: m_building = np.zeros(self.img_size, dtype=np.uint8)\n",
    "            if m_aguada is None: m_aguada = np.zeros(self.img_size, dtype=np.uint8)\n",
    "            if m_platform is None: m_platform = np.zeros(self.img_size, dtype=np.uint8)\n",
    "\n",
    "            m_building = cv2.resize(m_building, self.img_size)\n",
    "            m_aguada = cv2.resize(m_aguada, self.img_size)\n",
    "            m_platform = cv2.resize(m_platform, self.img_size)\n",
    "\n",
    "            combined_mask = np.stack([m_building, m_aguada, m_platform], axis=-1)\n",
    "            Y[i,] = 1.0 - (combined_mask / 255.0)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "# JeneratÃ¶rleri oluÅŸturuyoruz! (480x480 yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼k iÃ§in Batch Size 2 yapÄ±ldÄ±)\n",
    "print(\"EÄŸitim ve Test JeneratÃ¶rleri hazÄ±rlanÄ±yor...\")\n",
    "\n",
    "# Buradaki 8'leri silip 2 yaptÄ±k!\n",
    "train_gen = ChactunDataGenerator(LIDAR_PATH, MASK_PATH, 0, TRAIN_END, batch_size=2)\n",
    "test_gen = ChactunDataGenerator(LIDAR_PATH, MASK_PATH, TRAIN_END + 1, TEST_END, batch_size=2)\n",
    "\n",
    "print(\"JeneratÃ¶rler HazÄ±r! YÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ ve bellek dostu veri yÃ¼kleme aktif.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f64ab1",
   "metadata": {},
   "source": [
    "### Blok 3: VGG-19 TabanlÄ± U-Net Modeli (480x480)\n",
    "Bu blok, yapay zekanÄ±n beyin yapÄ±sÄ±nÄ± (mimariyi) oluÅŸturur. \n",
    "* **Encoder (Sol Kol):** GÃ¶rÃ¼ntÃ¼den Ã¶zellikleri (kenar, kÃ¶ÅŸe, ÅŸekil) Ã§Ä±karmak iÃ§in ImageNet Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸ VGG-19 modeli kullanÄ±lÄ±r (Transfer Learning). 1 kanallÄ± LiDAR verisi, modelin uyumluluÄŸu iÃ§in 3 kanala kopyalanÄ±r.\n",
    "* **Decoder (SaÄŸ Kol):** Ã‡Ä±karÄ±lan bu Ã¶zellikler, U-Net mimarisine Ã¶zgÃ¼ \"YukarÄ± Ã–rnekleme\" (UpSampling) ve \"Atlama BaÄŸlantÄ±larÄ±\" (Skip Connections) ile tekrar orijinal Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼ne (480x480) bÃ¼yÃ¼tÃ¼lÃ¼r.\n",
    "* **Ã‡Ä±kÄ±ÅŸ:** GÃ¶rÃ¼ntÃ¼deki her bir pikselin Bina, Su RezervuarÄ± veya Platform olma ihtimalini baÄŸÄ±msÄ±z olarak hesaplamak iÃ§in 3 kanallÄ± `Sigmoid` aktivasyon katmanÄ±yla biter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c1bce27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG-19 U-Net Modeli (480x480) oluÅŸturuluyor...\n",
      "Model: \"VGG19_UNET_480\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 480, 480, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 480, 480, 3)  0           ['input_2[0][0]',                \n",
      "                                                                  'input_2[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 480, 480, 64  1792        ['concatenate_5[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 480, 480, 64  36928       ['block1_conv1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 240, 240, 64  0           ['block1_conv2[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 240, 240, 12  73856       ['block1_pool[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 240, 240, 12  147584      ['block2_conv1[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 120, 120, 12  0           ['block2_conv2[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 120, 120, 25  295168      ['block2_pool[0][0]']            \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 120, 120, 25  590080      ['block3_conv1[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 120, 120, 25  590080      ['block3_conv2[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " block3_conv4 (Conv2D)          (None, 120, 120, 25  590080      ['block3_conv3[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 60, 60, 256)  0           ['block3_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 60, 60, 512)  1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 60, 60, 512)  2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 60, 60, 512)  2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv4 (Conv2D)          (None, 60, 60, 512)  2359808     ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 30, 30, 512)  0           ['block4_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 30, 30, 512)  2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 30, 30, 512)  2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 30, 30, 512)  2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv4 (Conv2D)          (None, 30, 30, 512)  2359808     ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 60, 60, 512)  0          ['block5_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 60, 60, 1024  0           ['up_sampling2d_4[0][0]',        \n",
      "                                )                                 'block4_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 60, 60, 512)  4719104     ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 60, 60, 512)  2359808     ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 120, 120, 51  0          ['conv2d_10[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 120, 120, 76  0           ['up_sampling2d_5[0][0]',        \n",
      "                                8)                                'block3_conv4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 120, 120, 25  1769728     ['concatenate_7[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 120, 120, 25  590080      ['conv2d_11[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 240, 240, 25  0          ['conv2d_12[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 240, 240, 38  0           ['up_sampling2d_6[0][0]',        \n",
      "                                4)                                'block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 240, 240, 12  442496      ['concatenate_8[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 240, 240, 12  147584      ['conv2d_13[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 480, 480, 12  0          ['conv2d_14[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 480, 480, 19  0           ['up_sampling2d_7[0][0]',        \n",
      "                                2)                                'block1_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 480, 480, 64  110656      ['concatenate_9[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 480, 480, 64  36928       ['conv2d_15[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 480, 480, 3)  195         ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 30,200,963\n",
      "Trainable params: 30,200,963\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications\n",
    "\n",
    "# DÄ°KKAT: GiriÅŸ boyutu artÄ±k 480x480!\n",
    "def build_vgg19_unet(input_shape=(480, 480, 1)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x_3ch = layers.Concatenate()([inputs, inputs, inputs])\n",
    "    base_vgg = applications.VGG19(include_top=False, weights='imagenet', input_tensor=x_3ch)\n",
    "    \n",
    "    # Skip Connections (480x480'e gÃ¶re otomatik boyutlanÄ±r)\n",
    "    s1 = base_vgg.get_layer(\"block1_conv2\").output \n",
    "    s2 = base_vgg.get_layer(\"block2_conv2\").output \n",
    "    s3 = base_vgg.get_layer(\"block3_conv4\").output \n",
    "    s4 = base_vgg.get_layer(\"block4_conv4\").output \n",
    "    \n",
    "    bridge = base_vgg.get_layer(\"block5_conv4\").output \n",
    "    \n",
    "    def upsample_block(x, skip, filters):\n",
    "        x = layers.UpSampling2D((2, 2))(x)\n",
    "        x = layers.Concatenate()([x, skip])\n",
    "        x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "        x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "        return x\n",
    "\n",
    "    d1 = upsample_block(bridge, s4, 512)\n",
    "    d2 = upsample_block(d1, s3, 256)\n",
    "    d3 = upsample_block(d2, s2, 128)\n",
    "    d4 = upsample_block(d3, s1, 64)\n",
    "    \n",
    "    outputs = layers.Conv2D(3, 1, activation=\"sigmoid\")(d4)\n",
    "    return models.Model(inputs, outputs, name=\"VGG19_UNET_480\")\n",
    "\n",
    "print(\"VGG-19 U-Net Modeli (480x480) oluÅŸturuluyor...\")\n",
    "model = build_vgg19_unet(input_shape=(480, 480, 1))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), \n",
    "    loss=\"binary_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f2d92",
   "metadata": {},
   "source": [
    "### Blok 4: Model EÄŸitimi (Training) ve Asistanlar (Callbacks)\n",
    "Bu blok, hazÄ±rlanan veri (Blok 2) ile model iskeletini (Blok 3) birleÅŸtirip Ã¶ÄŸrenme sÃ¼recini baÅŸlatÄ±r.\n",
    "EÄŸitim sÃ¼recini akÄ±llÄ±ca yÃ¶netmek iÃ§in 3 asistan (callback) kullanÄ±lÄ±r:\n",
    "1. **ModelCheckpoint:** Her epoch (tur) sonunda sadece baÅŸarÄ±sÄ± artan en iyi modeli kaydeder.\n",
    "2. **EarlyStopping:** Model belirli bir sÃ¼re (10 tur) geliÅŸmezse, boÅŸa vakit/enerji harcamamak iÃ§in eÄŸitimi erken durdurur.\n",
    "3. **ReduceLROnPlateau:** Model Ã¶ÄŸrenmekte zorlanmaya baÅŸladÄ±ÄŸÄ±nda (takÄ±ldÄ±ÄŸÄ±nda) adÄ±m boyutunu (learning rate) kÃ¼Ã§Ã¼lterek daha hassas Ã¶ÄŸrenmesini saÄŸlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a9f1101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EÄŸitim sÃ¼reci baÅŸlatÄ±lÄ±yor... RTX 4060 devreye giriyor ðŸš€\n",
      "Epoch 1/50\n",
      " 17/883 [..............................] - ETA: 2:28:30 - loss: 0.1482 - accuracy: 0.0699"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEÄŸitim sÃ¼reci baÅŸlatÄ±lÄ±yor... RTX 4060 devreye giriyor ðŸš€\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# Blok 2'deki eÄŸitim jeneratÃ¶rÃ¼\u001b[39;49;00m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Blok 2'deki test (doÄŸrulama) jeneratÃ¶rÃ¼\u001b[39;49;00m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     43\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alkay\\miniconda3\\envs\\ai_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\alkay\\miniconda3\\envs\\ai_env\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\alkay\\miniconda3\\envs\\ai_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\alkay\\miniconda3\\envs\\ai_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\alkay\\miniconda3\\envs\\ai_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\alkay\\miniconda3\\envs\\ai_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alkay\\miniconda3\\envs\\ai_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\alkay\\miniconda3\\envs\\ai_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\alkay\\miniconda3\\envs\\ai_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# En iyi modelin kaydedileceÄŸi klasÃ¶rÃ¼ oluÅŸturalÄ±m\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "# EÄŸitim AsistanlarÄ± (Callbacks)\n",
    "# 1. Her epoch sonunda sadece en iyi modeli (val_loss'a gÃ¶re) kaydeder\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"checkpoints/vgg19_unet_best.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 2. Model 10 tur boyunca ilerleme kaydetmezse eÄŸitimi erken bitirir\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 3. EÄŸitim duraklarsa Ã¶ÄŸrenme oranÄ±nÄ± (learning rate) dÃ¼ÅŸÃ¼rerek ince ayar yapar\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# EÄŸitimi BaÅŸlatÄ±yoruz!\n",
    "EPOCHS = 50\n",
    "print(\"EÄŸitim sÃ¼reci baÅŸlatÄ±lÄ±yor... RTX 4060 devreye giriyor ðŸš€\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,                   # Blok 2'deki eÄŸitim jeneratÃ¶rÃ¼\n",
    "    validation_data=test_gen,    # Blok 2'deki test (doÄŸrulama) jeneratÃ¶rÃ¼\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
